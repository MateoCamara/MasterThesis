# -*- coding: utf-8 -*-
"""similarity_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ujK11Vu0nwsLVGUsj26PRnVmHxb7fHMB

# IMPORTS
"""

!pip install keras_tqdm

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
import glob

os.environ['KERAS_BACKEND']='tensorflow'
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, TimeDistributed, LSTM, Reshape, ConvLSTM2D
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from keras.optimizers import Adam, SGD
from keras import backend as BK
from keras.models import Model
from sklearn.metrics import mean_squared_error
from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, Callback

from matplotlib import pyplot
from keras.preprocessing.image import img_to_array, load_img
from tqdm import tqdm_notebook as tqdm

import matplotlib.pyplot as plt
import seaborn as sns
from os import listdir
from os.path import isfile, join


from keras_tqdm import TQDMNotebookCallback

import threading
import random



# Any results you write to the current directory are saved as output.

"""# DEPENDENCIAS"""

working_on = 'grvide' # OR gdrive

image_type = 'full' # OR full OR reduced

if working_on == 'local':
  data_path = '../../media/mcl/My_Passport/mcl/frameDiffsGray/complexities_diffs_grayV2.csv'
  if image_type == 'cropped':
    path_imagenes = "/media/mcl/My_Passport/mcl/diffsGrayCropped/"
  elif image_type == 'full':
    path_imagenes = "/media/mcl/My_Passport/mcl/frameDiffsGray/reduced/descomprimidos/"
else:
  data_path = "./gdrive/My Drive/TFM/videos/complexities_diffs_gray_nocomunes.csv"
  path_imagenes_distorted = "./gdrive/My Drive/TFM/videos/diffsGray/"
  path_imagenes_original = "./gdrive/My Drive/TFM/videos/cuadros_directamente_del_video/"
  from google.colab import drive
  drive.mount('/content/gdrive')

"""#  VARIABLES GLOBALES"""

seq_length = int(248/5)
batch_size = 1
steps_per_epoch = 1

if image_type is 'reduced':
  rows = 270
  columns = 360
elif  image_type is 'cropped':
  rows = 540
  columns = 960
else:
  rows = 1080
  columns = 1920

quarter = "quarter0"

"""#CARGAR LOS DATOS"""

## DATOS NUMÉRICOS
data = pd.read_csv(data_path,index_col=None, header=0)
df_shuf = data.sample(frac=1, random_state=1)
dataset = df_shuf.values
dataset.shape

## DIRECTORIOS CON IMÁGENES
directorios_data = listdir(path_imagenes_distorted)
directorios_data.sort()
print(directorios_data)

## Limpieza de variables
del data, df_shuf, directorios_data

"""# SEPARAR ENTRE TRAIN Y TEST"""

X = dataset[:,0]
Y = dataset[:,23]

PERCENTAGE_SPLIT_TRAIN = 0.9

length_split_train = X.shape[0]*PERCENTAGE_SPLIT_TRAIN
length_split_train = int(length_split_train)

xtrain=X[0:length_split_train]
xtest=X[length_split_train:X.shape[0]]
ytrain=Y[0:length_split_train]
ytest=Y[length_split_train:X.shape[0]]

alv_test = np.matrix((xtest,ytest)).transpose()
test_data = alv_test.tolist()

alv = np.matrix((xtrain,ytrain)).transpose()
train_data = alv.tolist()

#PERCENTAGE_SPLIT_VALIDATION = 0.1

#length_split_validation = len(train_validation_data)*PERCENTAGE_SPLIT_VALIDATION
#length_split_validation = int(length_split_validation)

#validation_data = train_validation_data[0:length_split_validation]
#train_data = train_validation_data[length_split_validation:]

len(train_data)

## Limpieza de variables
del xtrain, ytrain, alv, alv_test

"""# CARGAR LAS IMÁGENES EN UN GENERADOR"""

## FUNCIÓN PARA CARGAR UNA IMAGEN COMO UN ARRAY EN NUMPY.

def process_image(image, target_shape):
    """Given an image, process it and return the array."""
    # Load the image.
    h, w = target_shape
    image = load_img(image, target_size=(h, w), color_mode = "grayscale")

    # Turn it into numpy, normalize and return.
    image = img_to_array(image)
    image = (image / 255.).astype(np.float32)

    return image

## EN ESTA RUTINA SE TOMAN LOS CUADROS DEL VÍDEO
def get_frames_for_sample_distorted(sample):
    """Given a sample row from the data file, get all the corresponding frame
    filenames."""
    
    """HE CAMBIADO QUE SAMPLE ERA SAMPLE[0]"""
    path = os.path.join(path_imagenes_distorted, sample)
    filename = sample#[0]
    images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))
    return images

## EN ESTA RUTINA SE TOMAN LOS CUADROS DEL VÍDEO
def get_frames_for_sample_original(sample):
    """Given a sample row from the data file, get all the corresponding frame
    filenames."""
    
    """HE CAMBIADO QUE SAMPLE ERA SAMPLE[0]"""
    path = os.path.join(path_imagenes_original, sample)
    filename = sample#[0]
    images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))
    return images

## MOVIDAS VARIAS PARA QUE EL GENERADOR NO PETE
def threadsafe_generator(func):
    """Decorator"""
    def gen(*a, **kw):
        return threadsafe_iterator(func(*a, **kw))
    return gen

class threadsafe_iterator:
    def __init__(self, iterator):
        self.iterator = iterator
        self.lock = threading.Lock()

    def __iter__(self):
        return self

    def __next__(self): ## HE CAMBIADO ESTO DE __next(self)__
        with self.lock:
            return next(self.iterator)

def grab_frames_in_order(images, index):
  output = images[index:(index+20)]
  #print(output)
  #print(str(len(output)))
  return output

## ESTO ES PARA REESCALAR EN CASO DE QUE NO SE QUIERA UTILIZAR TODAS LAS IMÁGENES
def rescale_list(input_list, size):
    """Given a list and a size, return a rescaled/samples list. For example,
    if we want a list of size 5 and we have a list of size 25, return a new
    list of size five which is every 5th element of the origina list."""
    assert len(input_list) >= size

    # Get the number to skip between iterations.
    skip = len(input_list) // size

    # Build our new output.
    output = [input_list[i] for i in range(0, len(input_list), skip)]

    # Cut off the last one if needed.
    return output[:size]

## CONSTRUIR UNA SECUENCIA A PARTIR DE LAS IMÁGENES
# creo que no es una verdadera secuencia, o sí, pero definitivamente no es un vídeo.
def build_image_sequence(frames):
    """Given a set of frames (filenames), build our sequence."""
    if image_type == 'cropped':
      return [process_image_cropped(x, [heigth, width]) for x in frames]
    else:
      return [process_image(x, [heigth, width]) for x in frames]

@threadsafe_generator
def frame_generator_train(batch_size, directorio_imagenes, train_data):
    """Return a generator that we can use to train on. There are
    a couple different things we can return:
    data_type: 'features', 'images'
    """
    index=0
    image_id=0

    
    while 1:
        #X = np.zeros(shape=(batch_size, 360, 270, 1), dtype="uint8")
        #y = np.zeros(shape=(batch_size, 1), dtype="uint8")
        frame_processed, y = [], []

        # Generate batch_size samples.

        sequence = None
        sample = train_data[index]
        #print("train index: "+str(index))
        index=index+1
        if index >= len(train_data)*248:
          index = 0
          print("reshuffle train data")
          random.shuffle(train_data)
        print('sample: '+str(sample[0])+'\n')
        frames = get_frames_for_sample_cropped(sample)
        print("todos los cuadros: "+str(frames))
        frame = frames[image_id]
        print("cuadro utilizado: " + str(frame) + " que cuadra con el id: " + str(image_id))
        image_id = image_id + 1
        if image_id > 248:
          image_id = 0
            
        frame_processed= [process_image_cropped(frame, [rows, columns])]
              
        y = sample[1]
        print("Salida train: "+ str(y))
        
        yield np.array(frame_processed), np.array(y)

@threadsafe_generator
def frame_generator_validation(batch_size, directorio_imagenes, validation_data):
    """Return a generator that we can use to train on. There are
    a couple different things we can return:
    data_type: 'features', 'images'
    """
    index=0
    
    while 1:
        #X = np.zeros(shape=(batch_size, 360, 270, 1), dtype="uint8")
        #y = np.zeros(shape=(batch_size, 1), dtype="uint8")
        frame_processed, y = [], []

        # Generate batch_size samples.
        sequence = None
        sample = validation_data[index]
        #print("validation index: "+str(index))
        index=index+1
        if index >= len(validation_data):
          index = 0
          #print("reshuffle validation data")
          random.shuffle(validation_data)
        print('sample validation: '+str(sample[0])+'\n')
        frames = get_frames_for_sample_cropped(sample)
        print("todos los cuadros validation: "+str(frames))
        frame = frames[image_id]
        print("cuadro utilizado validation: " + str(frame) + " que cuadra con el id: " + str(image_id))
        image_id = image_id + 1
        if image_id > 248:
          image_id = 0
        
        frame_processed= [process_image_cropped(frame, [rows, columns])]
        y = sample[1]
        print("Salida validation: "+ str(y))
            
        yield np.array(frame_processed), np.array(y)

@threadsafe_generator
def frame_generator_test(batch_size, directorio_imagenes, test_data):
    """Return a generator that we can use to train on. There are
    a couple different things we can return:
    data_type: 'features', 'images'
    """
    index=0
    
    while 1:
        #X = np.zeros(shape=(batch_size, 360, 270, 1), dtype="uint8")
        #y = np.zeros(shape=(batch_size, 1), dtype="uint8")
        X, y = [], []

        # Generate batch_size samples.
        for _ in range(batch_size):
            sequence = None
            sample = test_data[index]
            index=index+1
            #print('sample: '+sample[0]+'\n')
            frames = get_frames_for_sample_cropped(sample)
            #print("alv1")
            frames = rescale_list(frames, seq_length)
            #print(frames)
            # Build the image sequence
            sequence = build_image_sequence(frames)
            #print("alv3")

            X.append(sequence)
            #y.append(sample[1])

        yield np.array(X)#, np.array(y)

"""# GENERACIÓN DE LA RED NEURONAL"""

def model_similarity(rows,columns, deep):
    # initialize the input shape and channel dimension, assuming
    # TensorFlow/channels-last ordering
    inputShape = (1, 135, 240, 1)
    model = Sequential()

    model.add(Conv2D(64, (7, 7), 
        activation='relu',
                         padding='same', input_shape=inputShape, batch_input_shape=[1, 135, 240, 1]))
    model.add(MaxPooling2D((2, 2)  ))

    model.add(Conv2D(128, (3,3),
        kernel_initializer="he_normal", activation='relu'))
    model.add(MaxPooling2D((2, 2)  ))
    model.add(Conv2D(256, (3,3),
        padding='same', activation='relu'  ))
    model.add(MaxPooling2D((2, 2)   ))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(32400, activation='linear'))
  
    adam = Adam(lr=0.00001, decay=1e-6)
    model.compile(loss='mean_squared_error', optimizer=adam)
    
    return model

max_len = 248
class ResetStatesCallback(Callback):
    def __init__(self):
        self.counter = 0

    def on_batch_begin(self, batch, logs={}):
        if self.counter % max_len == 0:
            self.model.reset_states()
            print("SE RESETEAN PESOS")
        self.counter += 1

def get_model_memory_usage(batch_size, model):
    import numpy as np
    from keras import backend as K

    shapes_mem_count = 0
    for l in model.layers:
        single_layer_mem = 1
        for s in l.output_shape:
            if s is None:
                continue
            single_layer_mem *= s
        shapes_mem_count += single_layer_mem

    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])
    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])

    number_size = 4.0
    if K.floatx() == 'float16':
         number_size = 2.0
    if K.floatx() == 'float64':
         number_size = 8.0

    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)
    gbytes = np.round(total_memory / (1024.0 ** 3), 3)
    return gbytes

"""# ENTRENAMIENTO DE LA RED"""

model = model_similarity(rows, columns, 20)

print("Uso de memoria: " + str(get_model_memory_usage(batch_size, model)) + " GBytes")

# https://medium.com/singles/keras-callbacks-monitor-and-improve-your-deep-learning-205a8a27e91c

model.summary()

## NO SE PUEDE USAR TENSORBOARD CON DATOS DE VALIDACION QUE SEAN GENERADORES
#tbCallBack = TensorBoard(log_dir='./Graph3dCNN', histogram_freq=1, write_graph=True, write_images=True)

#checkpoints = ModelCheckpoint('./gdrive/My Drive/TFM/notebooks/checkpoints_3dCNN/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)

#history = model.fit_generator(frame_generator_train(batch_size, path_imagenes, train_data), validation_data = frame_generator_validation(batch_size, path_imagenes, validation_data), validation_steps=int(len(validation_data)/batch_size), max_queue_size=1, verbose=2, use_multiprocessing=False, workers=1, epochs=2, steps_per_epoch=int(len(train_data)/batch_size), shuffle=False, callbacks=[TQDMNotebookCallback()])

"""# LOCURA"""

model.save('./gdrive/My Drive/TFM/notebooks/checkpoints_similarity/checkpoint_similarity_epoch'+ str(epoch)+'_val'+str(np.mean(mean_te_loss))+'.h5')

from IPython.display import display, clear_output
print('Train...')
heigth=1080
width=1920
for epoch in tqdm(range(1)):
    mean_tr_loss = []
    mean_te_loss = []
    for i in tqdm(range(int(len(train_data)))): #len(train_data)
      sample = train_data[i][0]
      for image_id in tqdm(np.linspace(1,241, 49)):
        #print('sample: '+str(sample)+'\n')
        cuadros_distorted = get_frames_for_sample_distorted(sample)
        cuadros_orig = get_frames_for_sample_original(sample)
        frame_distorted = cuadros_distorted[int(image_id)]
        frame_orig = cuadros_orig[int(image_id)]
        frame_distorted_processed = [process_image(frame_distorted,[rows,columns])]
        frame_orig_processed = [process_image(frame_orig,[rows,columns])]
        frame_distorted_processed = np.array(frame_distorted_processed)
        frame_orig_processed = np.array(frame_orig_processed)
        
        for horizontal in range(4):
          for vertical in range(4):
            horizontal = int(horizontal)
            vertical = int(vertical)
            patch_distorted = frame_distorted_processed[:, int((horizontal)*135):int((horizontal+1)*135), int((vertical))*240:int((vertical+1)*240)]
            patch_orig = frame_orig_processed[:, int((horizontal)*135):int((horizontal+1)*135), int((vertical)*240):int((vertical+1)*240)]
            patch_distorted = np.expand_dims(np.reshape(patch_distorted, 32400),0)
            tr_loss = model.train_on_batch(patch_orig, patch_distorted)
            mean_tr_loss.append(tr_loss)
            print('\r', "Error en la secuencia "+ sample +": " + str(tr_loss), end='')
        
        #print("todos los cuadros: "+str(frames))
        #frame = frames[image_id]
        #print("cuadro utilizado: " + str(frame) + " que cuadra con el id: " + str(image_id))
        #frames_processed = build_image_sequence(frames)
        #frame_processed = [process_image(frame, [rows, columns])]
        #sequence = np.array(frames_processed)[:,:,:,0]
        #sequence.shape
        
        
        #mean_tr_acc.append(tr_acc)
        
        
        #if i == 200 or i == 300:
        #  model.save('./gdrive/My Drive/TFM/notebooks/checkpoints_LSTM_truncated/modelo_vuelta'+i+'.h5')
        
      
    print('\nloss training = {}'.format(np.mean(mean_tr_loss)))
    print('___________________________________')
    random.Random(1).shuffle(train_data)
    mean_tr_loss = []
    
    for i in tqdm(range(int(len(test_data)/30))):
      sample = test_data[i][0]
      for image_id in tqdm(range(248)):
        cuadros_distorted = get_frames_for_sample_distorted(sample)
        cuadros_orig = get_frames_for_sample_original(sample)
        frame_distorted = cuadros_distorted[int(image_id)]
        frame_orig = cuadros_orig[int(image_id)]
        frame_distorted_processed = [process_image(frame_distorted,[rows,columns])]
        frame_orig_processed = [process_image(frame_orig,[rows,columns])]
        frame_distorted_processed = np.array(frame_distorted_processed)
        frame_orig_processed = np.array(frame_orig_processed)
        
        for horizontal in range(4):
          for vertical in range(4):
            horizontal = int(horizontal)
            vertical = int(vertical)
            patch_distorted = frame_distorted_processed[:, int((horizontal)*135):int((horizontal+1)*135), int((vertical))*240:int((vertical+1)*240)]
            patch_orig = frame_orig_processed[:, int((horizontal)*135):int((horizontal+1)*135), int((vertical)*240):int((vertical+1)*240)]
            patch_distorted = np.expand_dims(np.reshape(patch_distorted, 32400),0)
            tr_loss = model.test_on_batch(patch_orig, patch_distorted)
            mean_te_loss.append(te_loss)
            print('\r', "Error en la secuencia "+ sample +": " + str(tr_loss), end='')

        
      

    print('loss testing = {}'.format(np.mean(mean_te_loss)))
    print('___________________________________')
    model.save('./gdrive/My Drive/TFM/notebooks/checkpoints_similarity/checkpoint_similarity_epoch'+ str(epoch)+'_val'+str(np.mean(mean_te_loss))+'.h5')

from keras.models import load_model
model = load_model('./gdrive/My Drive/TFM/notebooks/checkpoints_LSTM_truncated/modelo.h5')

prediction_global = np.zeros(int(len(train_data)/250)+3)
mean_prediction = []
for i in tqdm(range(int(len(train_data)/250)+3)):
  y_true = train_data[i][1]
  sample = train_data[i][0]
  cuadros = get_frames_for_sample(sample)
  for image_id in tqdm(np.linspace(0, 200, 9)):
    #print('sample: '+str(sample)+'\n')
    frames = grab_frames_in_order(cuadros, int(image_id))
    #print("todos los cuadros: "+str(frames))
    #frame = frames[image_id]
    #print("cuadro utilizado: " + str(frame) + " que cuadra con el id: " + str(image_id))
    frames_processed = build_image_sequence(frames)
    #frame_processed = [process_image(frame, [rows, columns])]
    sequence = np.array(frames_processed)[:,:,:,0]
    prediction = model.predict_on_batch(np.expand_dims(np.expand_dims(sequence, axis=1), axis=0))
    mean_prediction.append(prediction)
    print('\r', "Predicción para el minibatch " + str(image_id) + " en la secuencia "+ sample +": " + str(prediction), end='')
    #mean_tr_acc.append(tr_acc)
  model.reset_states()
  prediction_global[i] = prediction#np.mean(mean_prediction)
  print("\npredicción: " + str(prediction_global[i]) + ", real: " + str(y_true))

train_data[1][0]

actual_prediction = 0
prediction = np.zeros(len(train_data))
for i in tqdm(range(int(len(train_data)))):
  y_true = train_data[i][1]
  sample = train_data[i][0]
  for image_id in np.linspace(1,25,1):#tqdm(range(248)):
    #print('sample: '+str(sample)+'\n')
    image_id = int(image_id)
    frames_distorted = get_frames_for_sample(sample)
    frame_distorted = frames_distorted[image_id]
    

    frame_processed_distorted = [process_image(frame_distorted, [rows, columns])]


    Ø = [np.expand_dims(np.array(frame_processed_distorted),axis=0), np.expand_dims(np.array(frame_processed_original),axis=0),
          np.expand_dims(objective_values[i], axis=0)]

    actual_prediction += model.predict_on_batch(Ø)

    #mean_tr_acc.append(tr_acc)
  
  prediction[i] = actual_prediction/4
  actual_prediction = 0


print("predicción: " + str(prediction) + ", real: " + str(test_data))

'''
    mean_te_acc = []
    mean_te_loss = []
    for i in range(len(X_test)):
        for j in range(max_len):
            te_loss, te_acc = model.test_on_batch(np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1),
                                                  y_test[i])
            mean_te_acc.append(te_acc)
            mean_te_loss.append(te_loss)
        model.reset_states()

        for j in range(max_len):
            y_pred = model.predict_on_batch(np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1))
        model.reset_states()

    print('accuracy testing = {}'.format(np.mean(mean_te_acc)))
    print('loss testing = {}'.format(np.mean(mean_te_loss)))
    print('___________________________________')



              #X = np.zeros(shape=(batch_size, 360, 270, 1), dtype="uint8")
        #y = np.zeros(shape=(batch_size, 1), dtype="uint8")
        frame_processed, y = [], []

        # Generate batch_size samples.

        sequence = None
        sample = train_data[index]
        #print("train index: "+str(index))
        index=index+1
        if index >= len(train_data)*248:
          index = 0
          print("reshuffle train data")
          random.shuffle(train_data)
        print('sample: '+str(sample[0])+'\n')
        frames = get_frames_for_sample(sample)
        print("todos los cuadros: "+str(frames))
        frame = frames[image_id]
        print("cuadro utilizado: " + str(frame) + " que cuadra con el id: " + str(image_id))
        image_id = image_id + 1
        if image_id > 248:
          image_id = 0
            
        frame_processed= [process_image(frame, [rows, columns])]
              
        y = sample[1]
        print("Salida train: "+ str(y))
        
        yield np.array(frame_processed), np.array(y)
        '''

"""# TESTEO"""

prediction = model.predict_generator(frame_generator_test(batch_size, path_imagenes, test_data), steps = len(test_data))

mean_squared_error(ytest, prediction)

pyplot.figure(figsize=(20,10))
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

plt.figure(figsize=(20,10))
plt.scatter(ytest, prediction,  color='red')

plt.show()

print(prediction[22])
print(ytest[22])

i = 0
prediction_adjusted = prediction
for value in tqdm(prediction_adjusted):
  if value >= 5:
    prediction_adjusted[i] = 5
  elif value <= 1:
    prediction_adjusted[i] = 1
  
  i=i+1

mean_squared_error(ytest, prediction_adjusted)

plt.figure(figsize=(20,10))
plt.scatter(ytest, prediction,  color='red')

plt.show()